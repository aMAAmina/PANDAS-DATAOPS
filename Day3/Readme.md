### Goals:

#### Part1: Memory Optimization & Chunked Processing for Large Datasets
- [memory_pd.py](memory_pd.py) -Analyze memory usage of dataframes
- Optimize memory by changing data types:
    (Downcasting: Downcasting is changing a data type to a smaller, more specific variant, without loosing information
    ++ helps reduce memory usage without changing the values or behavior of your data.)
- Load and process massive files using chunking strategies
- Apply lazy evaluation techniques for big data
- Build scalable data ingestion pipelines for preprocessing